{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>567900433542488064</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ColeyGirouard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir I am scheduled for the morning, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-17 20:16:29 -0800</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569989168903819264</td>\n",
       "      <td>positive</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WalterFaddoul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir seeing your workers time in and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 14:36:22 -0800</td>\n",
       "      <td>Indianapolis, Indiana; USA</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>568089179520954368</td>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LocalKyle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united Flew ORD to Miami and back and  had gr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-18 08:46:29 -0800</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>568928195581513728</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amccarthy19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir @dultch97 that's horse radish üò§üê¥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 16:20:26 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>568594180014014464</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J_Okayy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united so our flight into ORD was delayed bec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 18:13:11 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment    airline airline_sentiment_gold  \\\n",
       "0  567900433542488064          negative  Southwest                    NaN   \n",
       "1  569989168903819264          positive  Southwest                    NaN   \n",
       "2  568089179520954368          positive     United                    NaN   \n",
       "3  568928195581513728          negative  Southwest                    NaN   \n",
       "4  568594180014014464          negative     United                    NaN   \n",
       "\n",
       "            name negativereason_gold  retweet_count  \\\n",
       "0  ColeyGirouard                 NaN              0   \n",
       "1  WalterFaddoul                 NaN              0   \n",
       "2      LocalKyle                 NaN              0   \n",
       "3    amccarthy19                 NaN              0   \n",
       "4        J_Okayy                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  @SouthwestAir I am scheduled for the morning, ...         NaN   \n",
       "1  @SouthwestAir seeing your workers time in and ...         NaN   \n",
       "2  @united Flew ORD to Miami and back and  had gr...         NaN   \n",
       "3     @SouthwestAir @dultch97 that's horse radish üò§üê¥         NaN   \n",
       "4  @united so our flight into ORD was delayed bec...         NaN   \n",
       "\n",
       "               tweet_created              tweet_location  \\\n",
       "0  2015-02-17 20:16:29 -0800             Washington D.C.   \n",
       "1  2015-02-23 14:36:22 -0800  Indianapolis, Indiana; USA   \n",
       "2  2015-02-18 08:46:29 -0800                    Illinois   \n",
       "3  2015-02-20 16:20:26 -0800                         NaN   \n",
       "4  2015-02-19 18:13:11 -0800                         NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0      Atlantic Time (Canada)  \n",
       "1  Central Time (US & Canada)  \n",
       "2  Central Time (US & Canada)  \n",
       "3      Atlantic Time (Canada)  \n",
       "4  Eastern Time (US & Canada)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>569682010270101504</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zsalim03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir In car gng to DFW. Pulled over 1h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 18:15:50 -0800</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569608307184242688</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sa_craig</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir after all, the plane didn‚Äôt land ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 13:22:57 -0800</td>\n",
       "      <td>College Station, TX</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>567879304593408001</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DanaChristos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>@SouthwestAir can't believe how many paying cu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-17 18:52:31 -0800</td>\n",
       "      <td>CT</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>569757651539660801</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rossj987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@USAirways I can legitimately say that I would...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 23:16:24 -0800</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>569900705852608513</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tranpham18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir still no response from AA. great ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 08:44:51 -0800</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id     airline airline_sentiment_gold          name  \\\n",
       "0  569682010270101504    American                    NaN      zsalim03   \n",
       "1  569608307184242688    American                    NaN      sa_craig   \n",
       "2  567879304593408001   Southwest                    NaN  DanaChristos   \n",
       "3  569757651539660801  US Airways                    NaN      rossj987   \n",
       "4  569900705852608513    American                    NaN    tranpham18   \n",
       "\n",
       "  negativereason_gold  retweet_count  \\\n",
       "0                 NaN              0   \n",
       "1                 NaN              0   \n",
       "2                 NaN              1   \n",
       "3                 NaN              0   \n",
       "4                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  @AmericanAir In car gng to DFW. Pulled over 1h...         NaN   \n",
       "1  @AmericanAir after all, the plane didn‚Äôt land ...         NaN   \n",
       "2  @SouthwestAir can't believe how many paying cu...         NaN   \n",
       "3  @USAirways I can legitimately say that I would...         NaN   \n",
       "4  @AmericanAir still no response from AA. great ...         NaN   \n",
       "\n",
       "               tweet_created       tweet_location               user_timezone  \n",
       "0  2015-02-22 18:15:50 -0800                Texas  Central Time (US & Canada)  \n",
       "1  2015-02-22 13:22:57 -0800  College Station, TX  Central Time (US & Canada)  \n",
       "2  2015-02-17 18:52:31 -0800                   CT  Eastern Time (US & Canada)  \n",
       "3  2015-02-22 23:16:24 -0800     Washington, D.C.  Eastern Time (US & Canada)  \n",
       "4  2015-02-23 08:44:51 -0800        New York City  Eastern Time (US & Canada)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        @SouthwestAir I am scheduled for the morning, ...\n",
       "1        @SouthwestAir seeing your workers time in and ...\n",
       "2        @united Flew ORD to Miami and back and  had gr...\n",
       "3           @SouthwestAir @dultch97 that's horse radish üò§üê¥\n",
       "4        @united so our flight into ORD was delayed bec...\n",
       "5        @united Why did you load us in this flying sar...\n",
       "6        @JetBlue that is a stock response. Delays not ...\n",
       "7        @JetBlue That'd be nice! Hoping to rack up eno...\n",
       "8        @united frankly worse customer service ever. P...\n",
       "9        @SouthwestAir yeah haha. Never been in one. It...\n",
       "10       @SouthwestAir MCO-&gt;DCA flight almost full o...\n",
       "11       @JetBlue what's the easiest way to get a ticke...\n",
       "12       @USAirways - love the changes in the lounge - ...\n",
       "13       @SouthwestAir I receive bad customer service a...\n",
       "14       @USAirways you're killing me sche a flight to ...\n",
       "15       @USAirways 8 weeks to refund this ticket - 037...\n",
       "16       @AmericanAir no private msg me and will provid...\n",
       "17       can you not? RT @JetBlue Our fleet's on fleek....\n",
       "18       @JetBlue any info on why flight 704 from SJU t...\n",
       "19       @AmericanAir, I've tried no less than 8 times ...\n",
       "20       @USAirways new problem...had wrong last name o...\n",
       "21       @SouthwestAir Any possible chance of SWA bring...\n",
       "22       @USAirways @AmericanAir who runs the show at t...\n",
       "23       @united computers are down but you stopped giv...\n",
       "24               @united good fly!! #United #businessFirst\n",
       "25       @united I am flying from msp to dxb, my child ...\n",
       "26       @JetBlue loves Cancelled Flightling tickets an...\n",
       "27       @united In ORD, waited 20 min after crew membe...\n",
       "28       @SouthwestAir Jason (108639) at Gate #3 in SAN...\n",
       "29       @AmericanAir everything for sorted out. Thanks...\n",
       "                               ...                        \n",
       "10950    @JetBlue Even though this flight #226 didn't h...\n",
       "10951    @SouthwestAir very disappointed in your handli...\n",
       "10952    @SouthwestAir flight Cancelled Flightled out o...\n",
       "10953    @united when I read it say ' in some cases' ca...\n",
       "10954    @SouthwestAir you're giving everyone tix for #...\n",
       "10955    @JetBlue Am I the only one who had to look tha...\n",
       "10956                      @SouthwestAir go south everyone\n",
       "10957    @USAirways 4 hours Late Flightr And i lost my ...\n",
       "10958    @united I sure did.   I had to drive a total o...\n",
       "10959    @USAirways his name is Rett Cavan, he has a go...\n",
       "10960    @united 3 times my flight has been delayed and...\n",
       "10961    @JetBlue there is no supervisor available, so ...\n",
       "10962                                    @united following\n",
       "10963    @USAirways even alternate options are allready...\n",
       "10964    @united Also your at-gate monitor showed 23 em...\n",
       "10965                               @united Okay thank you\n",
       "10966    @united - vacation days: relevant, Ritz in PR ...\n",
       "10967    @SouthwestAir you guys there? Are we on hour 2...\n",
       "10968    @AmericanAir we are through. I can quit you. I...\n",
       "10969            @SouthwestAir thank you! ‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è you guys!\n",
       "10970    @SouthwestAir went to purchase a flight that I...\n",
       "10971    @JetBlue by any chance do u offer fresh guacam...\n",
       "10972    @USAirways - 53 minutes on hold for a reservat...\n",
       "10973    @AmericanAir the worst air experience I have e...\n",
       "10974    @SouthwestAir beautiful view flying into San J...\n",
       "10975                              @AmericanAir followback\n",
       "10976    @united thanks for the help. Wish the phone re...\n",
       "10977    @usairways the. Worst. Ever. #dca #customerser...\n",
       "10978    @nrhodes85: look! Another apology. DO NOT FLY ...\n",
       "10979    @united you are by far the worst airline. 4 pl...\n",
       "Name: text, Length: 10980, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train['airline_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        negative\n",
       "1        positive\n",
       "2        positive\n",
       "3        negative\n",
       "4        negative\n",
       "5        negative\n",
       "6        negative\n",
       "7        positive\n",
       "8        negative\n",
       "9        positive\n",
       "10       negative\n",
       "11        neutral\n",
       "12       positive\n",
       "13       negative\n",
       "14       negative\n",
       "15       negative\n",
       "16       negative\n",
       "17       negative\n",
       "18       negative\n",
       "19       negative\n",
       "20       negative\n",
       "21        neutral\n",
       "22       negative\n",
       "23       negative\n",
       "24       positive\n",
       "25        neutral\n",
       "26       negative\n",
       "27       negative\n",
       "28       positive\n",
       "29       positive\n",
       "           ...   \n",
       "10950    positive\n",
       "10951    negative\n",
       "10952    negative\n",
       "10953    negative\n",
       "10954    negative\n",
       "10955    negative\n",
       "10956     neutral\n",
       "10957    negative\n",
       "10958    negative\n",
       "10959    negative\n",
       "10960    negative\n",
       "10961    negative\n",
       "10962     neutral\n",
       "10963    negative\n",
       "10964    negative\n",
       "10965     neutral\n",
       "10966    negative\n",
       "10967    negative\n",
       "10968    negative\n",
       "10969    positive\n",
       "10970    negative\n",
       "10971     neutral\n",
       "10972    negative\n",
       "10973    negative\n",
       "10974    positive\n",
       "10975     neutral\n",
       "10976    positive\n",
       "10977    negative\n",
       "10978    negative\n",
       "10979    negative\n",
       "Name: airline_sentiment, Length: 10980, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       @AmericanAir In car gng to DFW. Pulled over 1h...\n",
       "1       @AmericanAir after all, the plane didn‚Äôt land ...\n",
       "2       @SouthwestAir can't believe how many paying cu...\n",
       "3       @USAirways I can legitimately say that I would...\n",
       "4       @AmericanAir still no response from AA. great ...\n",
       "5       @united we have developers flying down tmrw mo...\n",
       "6                       @USAirways hello??? Anyone there?\n",
       "7       @USAirways @husainhaqqani Mr. Husain u shld pr...\n",
       "8       @USAirways not likely, flightaware says plane ...\n",
       "9       @AmericanAir they don't even give an option to...\n",
       "10      @united your announcement for pre boarding onl...\n",
       "11      @USAirways it is really embarrassing when aski...\n",
       "12      @SouthwestAir I will not have my passport in t...\n",
       "13      @AmericanAir this delayed bag was for my frien...\n",
       "14      @SouthwestAir Didn't see travel had to be comp...\n",
       "15      @USAirways awesome... Doors close in 2 minutes...\n",
       "16      @united I flew United last month and the exper...\n",
       "17      @JetBlue Accepting #Apple Pay - Mobile Enterpr...\n",
       "18      @united $55 cab ride to dfw from love got me m...\n",
       "19      @JetBlue ill call in the morning. too upset ri...\n",
       "20      @SouthwestAir @AARP #tfw1 Appreciate the tweet...\n",
       "21      @united what's the status of flight 1008 Bogot...\n",
       "22      @AmericanAir literally just stopped allowing p...\n",
       "23      @AmericanAir I really want to get home. Tonigh...\n",
       "24      @USAirways I've been on hold at the reservatio...\n",
       "25      @JetBlue Denver-Boston 2/10 flight 994  and Bo...\n",
       "26      @AmericanAir nothing to do with Mother Nature,...\n",
       "27      @USAirways you would rather a while plane get ...\n",
       "28      @JetBlue hi guys, do you have a general enquir...\n",
       "29      @united we finally just arrive to Bogota, good...\n",
       "                              ...                        \n",
       "3630                           @USAirways nope not yet...\n",
       "3631    @SouthwestAir So far so good! http://t.co/16c9...\n",
       "3632    @SouthwestAir @CBSsoxfan you get to hold? call...\n",
       "3633    @JetBlue Really!? That's good to hear! Thanks ...\n",
       "3634    @JetBlue trying to charge us $550 dollars cash...\n",
       "3635    @USAirways can u tell me if 5238 from clt to J...\n",
       "3636    @USAirways Your customer service is  non-exist...\n",
       "3637    @SouthwestAir Whoa. Thanks and that's what I w...\n",
       "3638    @United THANK U! Secured room for the night Th...\n",
       "3639    @AmericanAir I'm not sure what happened to my ...\n",
       "3640    @AmericanAir pretty bad at #DFW no updates two...\n",
       "3641    @USAirways Just contaced EYEWITNESS NEWS about...\n",
       "3642    @SouthwestAir thx. Make it right. Help Meagan ...\n",
       "3643    @USAirways I didn't Cancelled Flight my flight...\n",
       "3644    @united your \"Airserv\" contractors aren't wort...\n",
       "3645    @SouthwestAir @taylormdowns We share that valu...\n",
       "3646    @USAirways on hold now over 2 hrs on one phone...\n",
       "3647    @AmericanAir the flight I'm trying to change i...\n",
       "3648    @JetBlue the fact that #ChrisHasMadeUsBLUSH is...\n",
       "3649             @united Did somebody say flight upgrade?\n",
       "3650        @SouthwestAir how do I get my companion pass?\n",
       "3651    @USAirways tells me to talk to @AmericanAir ab...\n",
       "3652            @JetBlue you want me to talk to the wall?\n",
       "3653    @USAirways Now, the JFK Baggage Office has act...\n",
       "3654    @AmericanAir Least you could do would be to re...\n",
       "3655    @USAirways Been stuck for 40+ minutes due to l...\n",
       "3656    @USAirways 4 hours... 4 hours... FOUR HOURS.  ...\n",
       "3657    Nice RT @VirginAmerica: The man of steel might...\n",
       "3658    @AmericanAir Aww Thanks AA..DFW was on GMA up ...\n",
       "3659    @united the lounge tells us they have no pillo...\n",
       "Name: text, Length: 3660, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Chetna\n",
      "[nltk_data]     Agarwal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "punctuations = string.punctuation\n",
    "punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = [i for i in punctuations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words += p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(max_features=4000, ngram_range=(1,2), stop_words=stop_words, max_df = 0.8, lowercase = True, use_idf = True, smooth_idf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_train = vec.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_test = vec.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = {\"alpha\" :[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(clf, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(t_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf  = MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)\n",
    "clf.fit(t_train,y_train)\n",
    "predictions = clf.predict(t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'negative', 'negative', ..., 'negative', 'positive',\n",
       "       'negative'], dtype='<U8')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"final.csv\",predictions,delimiter=\",\",fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(t_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = clf1.predict(t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"final.csv\",predictions,delimiter=\",\",fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
